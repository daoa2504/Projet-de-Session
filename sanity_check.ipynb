{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Vérifions que les données sont valides en entraînant un SVM de la librairie `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "accu = utils.test_sklearn_svm(X_train, y_train, X_test, y_test)\n",
    "print('Test accuracy: {:.3f}'.format(accu))\n",
    "if accu < 0.7:\n",
    "    print('ERREUR: L\\'accuracy est trop faible. Il y a un problème avec les données. Vous pouvez essayer de refaire le mélange (case ci-haut).')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- S'assurer qu'une initialisation maximale donne une perte (loss) maximale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# En premier, vérifier la prédiction du modèle, la \"forward pass\"\n",
    "# 1. Générer le modèle avec des poids W aléatoires\n",
    "model = LinearClassifier(X_train, y_train, X_val, y_val, num_classes=3, bias=True)\n",
    "\n",
    "# 2. Appeler la fonction qui calcule l'accuracy et la loss moyenne pour l'ensemble des données d'entraînement\n",
    "_, loss = model.global_accuracy_and_cross_entropy_loss(X_train,y_train)\n",
    "\n",
    "# 3. Comparer au résultat attendu\n",
    "loss_attendu = -np.log(1.0/3.0) # résultat aléatoire attendu soit -log(1/nb_classes)\n",
    "print('Sortie: {}  Attendu: {}'.format(loss, loss_attendu))\n",
    "if abs(loss - loss_attendu) > 0.05:\n",
    "    print('ERREUR: la sortie de la fonction est incorrecte.')\n",
    "else:\n",
    "    print('SUCCÈS')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lorsque ça fonctionne, maintenant testons l'effet du terme de régularisation l2_reg.  **Augmenter le terme l2_reg devrait augmenter la loss et, à la limite, faire décroire l'accuracy **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Prenons encore un petit échantillon et testons différentes valeurs de l2_reg\n",
    "n_check = 5\n",
    "X_check = X_train[:n_check]\n",
    "y_check = y_train[:n_check]\n",
    "model = LinearClassifier(X_check, y_check, X_val, y_val, num_classes=3, bias=True)\n",
    "\n",
    "for l2_r in np.arange(0,1,0.05):\n",
    "    loss_train_curve, loss_val_curve, accu_train_curve, accu_val_curve = model.train(num_epochs=10, lr=1.0, l2_reg=l2_r)\n",
    "    print('l2_reg= {:.4f} >> Loss/accuracy d\\'entraînement : {:.3f} {:.3f}'.format(l2_r,loss_train_curve[-1],accu_train_curve[-1]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Vérifier qu'on peut overfitter sur un petit nombre de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Vérification: Vous devez pouvoir faire du surapprentissage sur quelques échantillons.\n",
    "# Si l'accuracy reste faible, votre implémentation a un bogue.\n",
    "n_check = 5\n",
    "X_check = X_train[:n_check]\n",
    "y_check = y_train[:n_check]\n",
    "model = LinearClassifier(X_check, y_check, X_val, y_val, num_classes=3, bias=True)\n",
    "loss_train_curve, loss_val_curve, accu_train_curve, accu_val_curve = model.train(num_epochs=10, lr=1.0, l2_reg=0.0)\n",
    "accu_train_finale = accu_train_curve[-1]\n",
    "print('Accuracy d\\'entraînement, devrait être 1.0: {:.3f}'.format(accu_train_finale))\n",
    "if accu_train_finale < 0.9999:\n",
    "    print('ATTENTION: L\\'accuracy n\\'est pas 100%.')\n",
    "    utils.plot_curves(loss_train_curve, loss_val_curve, accu_train_curve, accu_val_curve)\n",
    "else:\n",
    "    print('SUCCÈS')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
